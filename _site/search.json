[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "This is my personal blog or better my personal knowledge base where I am writing down my thoughts all around APIs, security, Linux, Python, data processing, natural language processing and more.\nLanguages I use are:\nPython Javascript\nThe tools I use:\nDjango Flask Reactjs Pyspark Git SQL Figma Azure Docker Heroku CircleCI\nReach out to me on my socials below."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "articles",
    "section": "",
    "text": "APIs\n\n\ntech\n\n\nprogramming\n\n\nengineering\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nAPIs\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nprogramming\n\n\nengineering\n\n\ndatabases\n\n\npostgres\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nprogramming\n\n\nengineering\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\ntech\n\n\nprogramming\n\n\nengineering\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\ngit\n\n\ngithub\n\n\nprogramming\n\n\nengineering\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\ntech\n\n\nprogramming\n\n\nengineering\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "How to keep your HTTP Cookies secure.",
    "section": "",
    "text": "The data they contain can be sensitive and personal, such as access tokens and session IDs, an obvious target for attackers. For this reason, securing them is vital.\nSecurely configuring cookies to keep their data safer should always be a priority if you decide your site requires them.\nBelow are the attributes you should know to ensure cookie securityüëáüèº\nSession vs. Persistent cookies\nCookies can be valid for a certain time using the ‚Äòmax-age‚Äô or ‚Äòexpires‚Äô attribute.\nUsing these makes a Cookie persistent, meaning it will persist even if the browser restarts as long as the expiry date is set sometime in the future.\nThe opposite of a persistent cookie is a session cookie when the ‚Äòmax-age‚Äô or ‚Äòexpires‚Äô attributes are omitted.\nSession cookies will expire automatically when the browser closes (the session ends).\nThe ‚ÄòSecure‚Äô Flag\nThe secure flag prevents a cookie from being sent over an unencrypted connection.\nYou should always use this when configuring cookies carrying sensitive data, as it will always be sent over HTTPS, which removes the risk of interception attacks.\nThe ‚ÄòHTTPOnly‚Äô Flag\nBy default, all cookies can be accessed and read by JavaScript.\nThe HTTPOnly flag tells the browser not to share the cookie with JavaScript by removing it from the ‚Äòwindow.cookie‚Äô variable, allowing it to stay hidden between the browser and server.\nThe ‚ÄòSameSite‚Äô Flag\nThis flag eliminates the risk of CSRF(Cross-Site-Request-Forgery). It prevents the cookie from being used in requests generated from different origins.\n‚ÄòSameSite‚Äô causes the browser to check if the request origin matches the origin that set the cookie.\nSummary\nNever store sensitive data in cookies unless it‚Äôs a necessity.\nAlways use the SameSite, HTTPOnly, and Secure flags.\nAim to use session cookies for sensitive data. If you use persistent cookies, keep their lifetime short and expire them soon.\nI hope you liked this thread!"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/How-to-keep-your-HTTP-Cookies-secure/index.html",
    "href": "posts/How-to-keep-your-HTTP-Cookies-secure/index.html",
    "title": "How to keep your HTTP Cookies secure.",
    "section": "",
    "text": "The data they contain can be sensitive and personal, such as access tokens and session IDs, an obvious target for attackers. For this reason, securing them is vital.\nSecurely configuring cookies to keep their data safer should always be a priority if you decide your site requires them.\nBelow are the attributes you should know to ensure cookie securityüëáüèº\nSession vs. Persistent cookies\nCookies can be valid for a certain time using the ‚Äòmax-age‚Äô or ‚Äòexpires‚Äô attribute.\nUsing these makes a Cookie persistent, meaning it will persist even if the browser restarts as long as the expiry date is set sometime in the future.\nThe opposite of a persistent cookie is a session cookie when the ‚Äòmax-age‚Äô or ‚Äòexpires‚Äô attributes are omitted.\nSession cookies will expire automatically when the browser closes (the session ends).\nThe ‚ÄòSecure‚Äô Flag\nThe secure flag prevents a cookie from being sent over an unencrypted connection.\nYou should always use this when configuring cookies carrying sensitive data, as it will always be sent over HTTPS, which removes the risk of interception attacks.\nThe ‚ÄòHTTPOnly‚Äô Flag\nBy default, all cookies can be accessed and read by JavaScript.\nThe HTTPOnly flag tells the browser not to share the cookie with JavaScript by removing it from the ‚Äòwindow.cookie‚Äô variable, allowing it to stay hidden between the browser and server.\nThe ‚ÄòSameSite‚Äô Flag\nThis flag eliminates the risk of CSRF(Cross-Site-Request-Forgery). It prevents the cookie from being used in requests generated from different origins.\n‚ÄòSameSite‚Äô causes the browser to check if the request origin matches the origin that set the cookie.\nSummary\nNever store sensitive data in cookies unless it‚Äôs a necessity.\nAlways use the SameSite, HTTPOnly, and Secure flags.\nAim to use session cookies for sensitive data. If you use persistent cookies, keep their lifetime short and expire them soon.\nI hope you liked this thread!"
  },
  {
    "objectID": "posts/HTTP-Cookies-secure/index.html",
    "href": "posts/HTTP-Cookies-secure/index.html",
    "title": "How to keep your HTTP Cookies secure.",
    "section": "",
    "text": "Cookies are small packets of data sent by the server and stored in the browser.\nThe data they contain can be sensitive and personal, such as access tokens and session IDs, an obvious target for attackers. For this reason, securing them is vital.\nSecurely configuring cookies to keep their data safer should always be a priority if you decide your site requires them.\nBelow are the attributes you should know to ensure cookie securityüëáüèº\nSession vs. Persistent cookies\nCookies can be valid for a certain time using the ‚Äòmax-age‚Äô or ‚Äòexpires‚Äô attribute.\nUsing these makes a Cookie persistent, meaning it will persist even if the browser restarts as long as the expiry date is set sometime in the future.\nThe opposite of a persistent cookie is a session cookie when the ‚Äòmax-age‚Äô or ‚Äòexpires‚Äô attributes are omitted.\nSession cookies will expire automatically when the browser closes (the session ends).\nThe ‚ÄòSecure‚Äô Flag\nThe secure flag prevents a cookie from being sent over an unencrypted connection.\nYou should always use this when configuring cookies carrying sensitive data, as it will always be sent over HTTPS, which removes the risk of interception attacks.\nThe ‚ÄòHTTPOnly‚Äô Flag\nBy default, all cookies can be accessed and read by JavaScript.\nThe HTTPOnly flag tells the browser not to share the cookie with JavaScript by removing it from the ‚Äòwindow.cookie‚Äô variable, allowing it to stay hidden between the browser and server.\nThe ‚ÄòSameSite‚Äô Flag\nThis flag eliminates the risk of CSRF(Cross-Site-Request-Forgery). It prevents the cookie from being used in requests generated from different origins.\n‚ÄòSameSite‚Äô causes the browser to check if the request origin matches the origin that set the cookie.\nSummary\nNever store sensitive data in cookies unless it‚Äôs a necessity.\nAlways use the SameSite, HTTPOnly, and Secure flags.\nAim to use session cookies for sensitive data. If you use persistent cookies, keep their lifetime short and expire them soon.\nI hope you liked this thread!"
  },
  {
    "objectID": "posts/rest-api/index.html",
    "href": "posts/rest-api/index.html",
    "title": "REST APIs",
    "section": "",
    "text": "REST API\nIt Is a web service based on REST architecture that allows communication between different systems.\nIt uses HTTP requests to GET, PUT, POST, and DELETE data. REST API is often used in web applications to access data from a server.\nAPI Client\nAn API Client is a software program that makes it easy to work with Application Programming Interfaces (APIs).\nIt can be used to access data or perform actions on behalf of a user.\nAPI Clients are often used by developers to test APIs.\nAPI Resource\nAn API resource is a specific type of data that can be accessed by an application programming interface (API). API Server\nAn API server allows two different systems to communicate with each other.\nIn most cases, an API server enables a web application to interact with a database.\nAPI Scalability\nAPI scalability refers to the ability of an API to handle increased loads of data or traffic without adversely affecting performance.\nA scalable API can handle large amounts of data and traffic without compromising speed or functionality.\nStateless API\nA stateless API is an API that does not maintain a state between requests.\nEach request is independent of any other request, and state information is not stored on the server.\nAPI Cache\nAn API is cacheable if the data it returns can be stored in a cache.\nCache allows the same data to be returned for multiple requests without having to fetch it from the original source each time.\nCaching can improve performance.\nLayered System\nA layered system, means that each layer is responsible for a specific set of tasks.\nThe most common layers are the presentation layer, the business logic layer, and the data access layer."
  },
  {
    "objectID": "posts/api-terms/index.html",
    "href": "posts/api-terms/index.html",
    "title": "API related terms",
    "section": "",
    "text": "Endpoint\nAn endpoint is nothing but the location(URL) where the actual resource is present.\nOrigin Server\nThe origin server is the actual server that contains the data and servers on the client‚Äôs request.\nThere may or may not be other intermediate servers included in the path.\nProxy Server\nServers have the ability to further pass your request to the other server.\nThese types of intermediate servers are known as proxy servers.\nDNS Server\nDNS stands for Domain Name System.\nAs computer devices are interacted using IP addresses, the DNS server provides the IP address of the requested URL.\nAPI key\nAn API key is a unique code for every user which lets you call an API.\nThe length of an API key could be anything.\nThe only rule is that these keys must be unique and not easy to guess.\nGenerally, API keys contain lower case and upper case letters with numbers.\nAPI Token\nThe API token is a unique identifier of an application requesting access to your API.\nAn API token is a form of authentication similar to a username/password.\nAccess token\nAn access token is used for authentication.\nApplications use an access token to authenticate themselves so that they can make an API call.\nSDK\nSDK stands for Software Development Kit.\nIt is a set of development tools that allows the creation of software or an application for a particular platform.\nSDK provides you with the whole package from compilers to debuggers to even a software development framework.\nRPC\nRemote Procedure Call (RPC) is the oldest client-server communication method in use today. Instead of the traditional HTTP call, RPC uses a function call.\nIt means that on the client-side, you invoke a function that is written on the server-side code.\nCORS\nCORS is an HTTP-based mechanism that lets you request data from one URL to a different URL.\nCheck out this note for more details: üëáüèª Screenshot from 2022-09-16 15-18-30\nAsync API\nAsyncAPI is an open-source project aimed at improving the current state of Event-Driven Architecture.\nThese APIs allow relatively time-consuming requests to be processed in the background while other requests are made.\nInternal API\nInternal API, also known as Private API is only accessible to the developers within an organization.\nAPI Caching\nAPI Caching is the ability to store copies of frequently accessed data in several places along the request-response path.\nExternal API\nExternal API, also known as Public API is accessible to all the developers outside the enterprise or organization.\nHTTP cookies\nAn HTTP cookie is a small piece of data created by the web server inside your browser.\nThe data inside a cookie has an ID that is unique to you and your computer. This ID helps the server know who the user is to send the data accordingly.\nAuthorization\nAuthorization always comes after authentication. It is the process of permitting users to access different resources from the server, and it‚Äôs not visible and changeable by the user.\nMicroservices\nA microservice is an application design that breaks up a monolithic architecture into small, self-containing services.\nOpenAPI spec\nIt is a format to define structure and syntax for REST APIs. It provides a standard that allows both humans and computers to discover and understand the service‚Äôs capabilities without access to source code, documentation, or traffic inspection.\nComposite API\nComposite API is a design approach in which we bundle multiple API requests into a single API call.\nAPI Versioning\nAPI versioning is the practice of managing changes in your API.\nYou should version your API if you are introducing any breaking changes. Clients can still access the old version, and their products will not break as soon as you launch a new release.\nAuthentication\nAuthentication and authorization are the two most confusing terms.\nAuthentication is validating the user to identify if they are who they claim to be.\nAPI Lifecycle\nAPI lifecycle is the entire lifespan of any particular API from its planning phase to when it gets stale."
  },
  {
    "objectID": "posts/setup-project/index.html",
    "href": "posts/setup-project/index.html",
    "title": "Set up projects for development and production environments",
    "section": "",
    "text": "This topic describes how to:\nUse separate projects to create development and production environments Many organizations have separate development and production environments so they can build and test new features without disturbing production traffic. In Optimizely, you can create separate projects for each environment to help with governance.\nWith separate development and production projects, your organization can safely build and QA experiments and Personalization campaigns in a development environment before deploying to production. This approach allows multiple stakeholders in your organization to act as gatekeepers for running new experiments in production.\nThis article describes how to set up projects for two separate environments and deploy experiments in that setup.\nSet up projects First, you‚Äôll start by creating two new projects: one for development and one for production.\nEach project will need its own snippet:\nCreate a project for your development environment.\nImplement the snippet in the head tag for that environment.\nAdd the collaborators who you'd like to have access to your development project.\nNext, create a project for your production environment.\nImplement the production project snippet in the head tag of the production environment.\nAdd collaborators who you'd like to have access to your production project.\nIf you‚Äôre using Optimizely, prepare each project by creating all pages, events, and audiences in each project. If you have an Optimizely Web Scale package, you can create events that are available across projects, which saves you time and makes it easier to keep events synchronized across your environments.\nCreate and deploy experiments Once you‚Äôve set up your development and production projects, use them to create, test, and deploy experiments. Here‚Äôs how:\nCreate an experiment in your development environment. If your development URLs are the same as the URLs used for your production environment, make sure that your production environment does not use the snippet from your development project.\nBuild and QA your new development experiment to make sure that everything works the way you‚Äôd like.\nBuild the experiment for your production project.\nWhen you‚Äôre ready, start the experiment in your production project!"
  },
  {
    "objectID": "posts/best-api-design-practices/index.html",
    "href": "posts/best-api-design-practices/index.html",
    "title": "API Design best practices",
    "section": "",
    "text": "Allow pagination and filtering\nSome endpoints may return substantial amounts of data that slow down a system.\nPagination and filtering avoid this by returning only a certain number of results at a time. This improves performance and reduces the usage of server resources.\nVersioning\nIf you‚Äôre making changes to your API that could potentially break it and the client apps that use it, it‚Äôs crucial to version it to have previous versions as a backup. This also lets you phase out old endpoints and introduce updated ones with new features.\nUse JSON\nJSON is the standard for transferring data. JavaScript has built-in methods to parse JSON quickly, and it is supported in almost all programming languages. For simplicity, APIs should accept JSON payloads, and endpoints should return JSON as a response.\nUse nouns for endpoint paths\nEndpoint paths should always be named in reference to the entity they represent, for example, ‚Äòarticles,‚Äô ‚Äòusers,‚Äô ‚Äòposts.‚Äô\nEndpoints paths should never be verbs because the HTTP request is our verb, e.g., GET, DELETE, PUT, etc.\nMaintain good security practices\nAs with any client-server communication, SSL/TLS security is a must if data is to be kept encrypted and safe. Without it, data is at risk of being exposed.\nUse caching\nUsing Cache-Control headers will allow users to make effective use of cached data.\nCaching allows users to access data faster because it is stored locally, meaning another request to the server to retrieve it is not needed.\nImplement timeouts\nTimeouts cause a request to fail after a specified amount of time.\nThis is useful when there is a network issue, and the request cannot be completed, or a user sends too much data.\nThis connection is closed instead of remaining open."
  },
  {
    "objectID": "posts/naming-conventions-for-git/index.html#table-of-content",
    "href": "posts/naming-conventions-for-git/index.html#table-of-content",
    "title": "Naming conventions and pull request naming",
    "section": "Table of Content",
    "text": "Table of Content\n\nBranch Naming\nCommit Message\n\nMessage Header\nMessage Body\nMessage Footer\nMessage Example"
  },
  {
    "objectID": "posts/naming-conventions-for-git/index.html#branch-naming",
    "href": "posts/naming-conventions-for-git/index.html#branch-naming",
    "title": "Naming conventions and pull request naming",
    "section": "Branch Naming",
    "text": "Branch Naming\nBranches created should be named using the following format:\n{story type}-{2-3 word summary}-{Asana work item id}\nstory-type - Indicates the context of the branch and can be one of:\n    ft == Feature\n    bg == Bug\n    ch == Chore\n    rf == Refactor\nstory-summary - Short 2-3 words summary about what the branch contains\nExample\nft-user-registration-TB1-I764"
  },
  {
    "objectID": "posts/naming-conventions-for-git/index.html#commit-message",
    "href": "posts/naming-conventions-for-git/index.html#commit-message",
    "title": "Naming conventions and pull request naming",
    "section": "Commit Message",
    "text": "Commit Message\nA commit message consists of a header, a body and a footer, separated by a blank line.\nAny line of the commit message cannot be longer than 100 characters! This allows the message to be easier to read on gitlab as well as in various git tools.\n<type>(<scope>): <subject>\n<BLANK LINE>\n<body>\n<BLANK LINE>\n<footer>\nThese rules are adopted from the AngularJS commit convention.\n\nMessage Header\nThe message header is a single line that contains succinct description of the change containing a type, an optional scope and a subject.\n##### <type> This describes the kind of change that this commit is providing.\nfeat (feature)\nfix (bug fix)\ndocs (documentation)\nstyle (formatting, missing semi colons, ‚Ä¶)\nrefactor\ntest (when adding missing tests)\nchore (maintain)\n#####<scope> Scope can be anything specifying place of the commit change. For example events, model_load, shiny_data_processing, authorization, authentication, loginPage, etc‚Ä¶\n#####<subject> This is a very short description of the change.\nuse imperative, present tense: ‚Äúchange‚Äù not ‚Äúchanged‚Äù nor ‚Äúchanges‚Äù\ndon‚Äôt capitalize first letter\nno dot (.) at the end\n\n\nMessage Body\njust as in subject use imperative, present tense: ‚Äúchange‚Äù not ‚Äúchanged‚Äù nor ‚Äúchanges‚Äù\nincludes motivation for the change and contrasts with previous behavior\nhttp://365git.tumblr.com/post/3308646748/writing-git-commit-messages\nhttp://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html Message Footer\n\n\nMessage Footer\nStatus changes should be listed on a separate line in the footer prefixed with #status  like this:\n[#TB1-I17 #status (in_progress | under_review)]\n\n\nMessage Example\nfeat(docker): implement exactly once delivery\n\nensure every event published to docker is delivered exactly once\nimplement error handling for failed delivery\n\n#status in_progress\nAsana cards"
  },
  {
    "objectID": "posts/naming-conventions-for-git/index.html#pull-request-naming",
    "href": "posts/naming-conventions-for-git/index.html#pull-request-naming",
    "title": "Naming conventions and pull request naming",
    "section": "Pull Request Naming",
    "text": "Pull Request Naming\n\nPull Request Title\nThe Pull Request title should be named using the following format:\n#[STORY_ID] [Story description]\nExample\n#TB1-I764 CREATE PULL REQUEST TEMPLATE\n\n\nPull Request Description Template\nThe description of the Pull Request should contain the following headings and corresponding content in Markdown format.\n#### What does this Pull Request do?\n#### Description of Task to be completed?\n#### How should this be manually tested?\n#### Any background context you want to provide?\n#### What are the relevant open projects stories e.g Asana?\n#### Screenshots (if appropriate)\n#### Questions:\n\n\nPull Request Etiquette\nIt is our belief that Pull Request reviews should not negatively impact a team‚Äôs ability to deliver features. Pull Requests that take too much time to get reviewed can hinder on a team‚Äôs progress. As such, we practice the following behaviours when raising Pull Requests:\nWhen I raise a Pull Request, I specifically assign a developer or engineering team as reviewer\nWhen I raise a Pull Request, I notify the reviewer(s) on telegram in a public channel\nThe reviewer(s) can re-assign the Pull Request to someone else (e.g. to a Senior Engineer)\nThe reviewer(s) has a 3 hours SLA to review the Pull Request\nIf SLA is not met, I can Pull the unreviewed Pull Request if and only if:\n    All the Pull Request checks are passing (CircleCI, CodeClimate, Test Coverage)\n    I communicate in #technology telegram channel that I am merging an unreviewed Pull Request\n    I immediately take ownership of fixing any issues that arise from merging the Pull Request"
  },
  {
    "objectID": "posts/naming-conventions-for-git/index.html",
    "href": "posts/naming-conventions-for-git/index.html",
    "title": "Naming conventions and pull request naming",
    "section": "",
    "text": "Branch Naming\nCommit Message\n\nMessage Header\nMessage Body\nMessage Footer\nMessage Example"
  },
  {
    "objectID": "posts/connect-python-postgres/index.html",
    "href": "posts/connect-python-postgres/index.html",
    "title": "Connect python with postgres database",
    "section": "",
    "text": "First run this in terminal:\n    pip install psycopg2\nCreate a new database\nLog in to the PostgreSQL database server and create a database.\nCreate database mlteam\n    CREATE DATABASE mlteam;\nConnect to the database using the psycopg2\nTo connect to mlteam database, use the connect() function of the psycopg2.\nThe connect() function creates a new database session and returns a new instance of the connection class. By using the connection object, you can create a new cursor to execute any SQL statements.\nTo call the connect() function, you specify the PostgreSQL database parameters as a connection string and pass it like this to the connect function:\n    conn = psycopg2.connect(\n\n                    host=\"localhost\",\n                    database=\"suppliers\",\n                    user=\"postgres\",\n                    password=\"Abcd1234\"\n                    \n                )\nList of the connection parameters:\n\ndatabase: the name of the database e.g mlteam.\nuser: the username used to authenticate.\npassword: password used to authenticate.\nhost: database server address e.g., localhost or an IP address.\nport: the port number that defaults to 5432/5433 if it is not provided.\n\nI highly recommend you to use a configuration file to store all connection parameters.\nContents of the mlteam.ini file:\n    [postgresql]\n    host=localhost\n    database=mlteam\n    user=postgres\n    password=verysecure@$password\nBy using the mlteam.ini, you can change the PostgreSQL connection parameters when you move the code to the production environment without modifying the code.\nIf you‚Äôre pushing code with git, include mlteam.ini to the .gitignore file to not committing the sensitive information to the public repo like github.\nThe .gitignore file will be like this:\n    mlteam.ini\nCreate the config.py file.\nThe following config() function read the mlteam.ini file and returns connection parameters. The config() function is placed in the config.py file:\nIt looks this way:\n    #!/usr/bin/python\n\n    from configparser import ConfigParser\n\n\n    def config(filename='mlteam.ini', section='postgresql'):\n        # create a parser\n        parser = ConfigParser()\n        # read config file\n        parser.read(filename)\n\n        # get section, default to postgresql\n        db = {}\n        if parser.has_section(section):\n            params = parser.items(section)\n            for param in params:\n                db[param[0]] = param[1]\n        else:\n            raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n\n        return db\nCreate connect.py file\nThe following connect() function connects to mlteam , prints out database version.\nconnect.py file:\n    #!/usr/bin/python\n    import psycopg2\n    from config import config\n\n    def connect():\n        \"\"\" Connect to the PostgreSQL database server \"\"\"\n        conn = None\n        try:\n            # read connection parameters\n            params = config()\n\n            # connect to the PostgreSQL server\n            print('Connecting to the PostgreSQL database...')\n            conn = psycopg2.connect(**params)\n            \n            # create a cursor\n            cur = conn.cursor()\n            \n        # execute a statement\n            print('PostgreSQL database version:')\n            cur.execute('SELECT version()')\n\n            # display the PostgreSQL database server version\n            db_version = cur.fetchone()\n            print(db_version)\n        \n        # close the communication with the PostgreSQL\n            cur.close()\n        except (Exception, psycopg2.DatabaseError) as error:\n            print(error)\n        finally:\n            if conn is not None:\n                conn.close()\n                print('Database connection closed.')\n\n\n    if __name__ == '__main__':\n        connect()\nThe process in code.\nFirst, it reads database connection parameters from the mlteam.ini file then creates a new database connection by calling the connect() function, it then creates a new cursor and execute an SQL statement to get database version. After that, read the result set by calling the fetchone() method of the cursor object. Finally, close the communication with the database server by calling the close() method of the cursor and connection object.\nExecute code by running the connect.py file.\nYou should see such result in terminal:\n    Connecting to the PostgreSQL database...\n    PostgreSQL database version:\n    ('PostgreSQL 13, compiled by Visual C++ build 1914, 64-bit',)\n    Database connection closed."
  }
]
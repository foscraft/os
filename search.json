[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "This is my personal blog or better my personal knowledge base where I am writing down my thoughts all around APIs, security, Linux, Python, data processing, natural language processing and more.\nLanguages I use are:\nPython Javascript\nThe tools I use:\nDjango Flask Reactjs Pyspark Git SQL Figma Azure Docker Heroku CircleCI\nReach out to me on my socials below."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "articles",
    "section": "",
    "text": "APIs\n\n\ntech\n\n\nprogramming\n\n\nengineering\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\nAPIs\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nLinux\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nprogramming\n\n\nengineering\n\n\ndatabases\n\n\npostgres\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nprogramming\n\n\nengineering\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\ntech\n\n\nprogramming\n\n\nengineering\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\ngit\n\n\ngithub\n\n\nprogramming\n\n\nengineering\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\ntech\n\n\nprogramming\n\n\nengineering\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nAPIs\n\n\ntech\n\n\nprogramming\n\n\nengineering\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\nfoscraft\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/best-api-design-practices/index.html",
    "href": "posts/best-api-design-practices/index.html",
    "title": "API Design best practices",
    "section": "",
    "text": "Allow pagination and filtering\nSome endpoints may return substantial amounts of data that slow down a system.\nPagination and filtering avoid this by returning only a certain number of results at a time. This improves performance and reduces the usage of server resources.\nVersioning\nIf you‚Äôre making changes to your API that could potentially break it and the client apps that use it, it‚Äôs crucial to version it to have previous versions as a backup. This also lets you phase out old endpoints and introduce updated ones with new features.\nUse JSON\nJSON is the standard for transferring data. JavaScript has built-in methods to parse JSON quickly, and it is supported in almost all programming languages. For simplicity, APIs should accept JSON payloads, and endpoints should return JSON as a response.\nUse nouns for endpoint paths\nEndpoint paths should always be named in reference to the entity they represent, for example, ‚Äòarticles,‚Äô ‚Äòusers,‚Äô ‚Äòposts.‚Äô\nEndpoints paths should never be verbs because the HTTP request is our verb, e.g., GET, DELETE, PUT, etc.\nMaintain good security practices\nAs with any client-server communication, SSL/TLS security is a must if data is to be kept encrypted and safe. Without it, data is at risk of being exposed.\nUse caching\nUsing Cache-Control headers will allow users to make effective use of cached data.\nCaching allows users to access data faster because it is stored locally, meaning another request to the server to retrieve it is not needed.\nImplement timeouts\nTimeouts cause a request to fail after a specified amount of time.\nThis is useful when there is a network issue, and the request cannot be completed, or a user sends too much data.\nThis connection is closed instead of remaining open."
  },
  {
    "objectID": "posts/HTTP-Cookies-secure/index.html",
    "href": "posts/HTTP-Cookies-secure/index.html",
    "title": "How to keep your HTTP Cookies secure.",
    "section": "",
    "text": "Securely configuring cookies to keep their data safer should always be a priority if you decide your site requires them.\nBelow are the attributes you should know to ensure cookie securityüëáüèº\nSession vs. Persistent cookies\nCookies can be valid for a certain time using the ‚Äòmax-age‚Äô or ‚Äòexpires‚Äô attribute.\nUsing these makes a Cookie persistent, meaning it will persist even if the browser restarts as long as the expiry date is set sometime in the future.\nThe opposite of a persistent cookie is a session cookie when the ‚Äòmax-age‚Äô or ‚Äòexpires‚Äô attributes are omitted.\nSession cookies will expire automatically when the browser closes (the session ends).\nThe ‚ÄòSecure‚Äô Flag\nThe secure flag prevents a cookie from being sent over an unencrypted connection.\nYou should always use this when configuring cookies carrying sensitive data, as it will always be sent over HTTPS, which removes the risk of interception attacks.\nThe ‚ÄòHTTPOnly‚Äô Flag\nBy default, all cookies can be accessed and read by JavaScript.\nThe HTTPOnly flag tells the browser not to share the cookie with JavaScript by removing it from the ‚Äòwindow.cookie‚Äô variable, allowing it to stay hidden between the browser and server.\nThe ‚ÄòSameSite‚Äô Flag\nThis flag eliminates the risk of CSRF(Cross-Site-Request-Forgery). It prevents the cookie from being used in requests generated from different origins.\n‚ÄòSameSite‚Äô causes the browser to check if the request origin matches the origin that set the cookie.\nSummary\nNever store sensitive data in cookies unless it‚Äôs a necessity.\nAlways use the SameSite, HTTPOnly, and Secure flags.\nAim to use session cookies for sensitive data. If you use persistent cookies, keep their lifetime short and expire them soon.\nI hope you liked this thread!"
  },
  {
    "objectID": "posts/linux-file-system/index.html",
    "href": "posts/linux-file-system/index.html",
    "title": "Linux Filesystem hierarchy",
    "section": "",
    "text": "/ - This is the root of your filesystem, where everything begins.\n/etc - This directory contains system configuration files.\n/home - This is the default home directory for all users (except the root user).\n/root - This is the home directory for the root user.\n/dev - This is where your devices such as your hard disks, USB drives, and optical drives reside on your system.\n/opt - This is where you can install additional 3rd party software.\n/boot - All the files required for your system to boot are stored here.\n/bin - This is where essential binaries (programs) reside on your system. In other words, your Linux commands executables.\n/sbin - This is where system binaries (programs) that are typically used by the system administrator are stored. Commands here require sudo access.\n/opt - This is where you can install additional 3rd party software (not coming from your distribution‚Äôs package manager).\n/tmp - This is where temporary files are stored; they are usually deleted after a system reboot, so never store important files here!\n/var - This directory contains files that may change in size, such as mail spools and log files. Many sysadmins store their web services here.\n/usr - This directory contains files and utilities that are shared between users.\n/lib - This directory contains libraries needed by the essential binaries in the /bin and /sbin directories. A library is basically a set of precompiled functions that can be used by a program.\n/proc - This is where information about running processes is stored.\nYou will have more files under your root (/) directory. I have only chosen the most important and common ones that should exist on every Linux distribution."
  },
  {
    "objectID": "posts/connect-python-postgres/index.html",
    "href": "posts/connect-python-postgres/index.html",
    "title": "Connect python with postgres database",
    "section": "",
    "text": "First run this in terminal:\n    pip install psycopg2\nCreate a new database\nLog in to the PostgreSQL database server and create a database.\nCreate database mlteam\n    CREATE DATABASE mlteam;\nConnect to the database using the psycopg2\nTo connect to mlteam database, use the connect() function of the psycopg2.\nThe connect() function creates a new database session and returns a new instance of the connection class. By using the connection object, you can create a new cursor to execute any SQL statements.\nTo call the connect() function, you specify the PostgreSQL database parameters as a connection string and pass it like this to the connect function:\n    conn = psycopg2.connect(\n\n                    host=\"localhost\",\n                    database=\"suppliers\",\n                    user=\"postgres\",\n                    password=\"Abcd1234\"\n                    \n                )\nList of the connection parameters:\n\ndatabase: the name of the database e.g mlteam.\nuser: the username used to authenticate.\npassword: password used to authenticate.\nhost: database server address e.g., localhost or an IP address.\nport: the port number that defaults to 5432/5433 if it is not provided.\n\nI highly recommend you to use a configuration file to store all connection parameters.\nContents of the mlteam.ini file:\n    [postgresql]\n    host=localhost\n    database=mlteam\n    user=postgres\n    password=verysecure@$password\nBy using the mlteam.ini, you can change the PostgreSQL connection parameters when you move the code to the production environment without modifying the code.\nIf you‚Äôre pushing code with git, include mlteam.ini to the .gitignore file to not committing the sensitive information to the public repo like github.\nThe .gitignore file will be like this:\n    mlteam.ini\nCreate the config.py file.\nThe following config() function read the mlteam.ini file and returns connection parameters. The config() function is placed in the config.py file:\nIt looks this way:\n    #!/usr/bin/python\n\n    from configparser import ConfigParser\n\n\n    def config(filename='mlteam.ini', section='postgresql'):\n        # create a parser\n        parser = ConfigParser()\n        # read config file\n        parser.read(filename)\n\n        # get section, default to postgresql\n        db = {}\n        if parser.has_section(section):\n            params = parser.items(section)\n            for param in params:\n                db[param[0]] = param[1]\n        else:\n            raise Exception('Section {0} not found in the {1} file'.format(section, filename))\n\n        return db\nCreate connect.py file\nThe following connect() function connects to mlteam , prints out database version.\nconnect.py file:\n    #!/usr/bin/python\n    import psycopg2\n    from config import config\n\n    def connect():\n        \"\"\" Connect to the PostgreSQL database server \"\"\"\n        conn = None\n        try:\n            # read connection parameters\n            params = config()\n\n            # connect to the PostgreSQL server\n            print('Connecting to the PostgreSQL database...')\n            conn = psycopg2.connect(`params)\n            \n            # create a cursor\n            cur = conn.cursor()\n            \n        # execute a statement\n            print('PostgreSQL database version:')\n            cur.execute('SELECT version()')\n\n            # display the PostgreSQL database server version\n            db_version = cur.fetchone()\n            print(db_version)\n        \n        # close the communication with the PostgreSQL\n            cur.close()\n        except (Exception, psycopg2.DatabaseError) as error:\n            print(error)\n        finally:\n            if conn is not None:\n                conn.close()\n                print('Database connection closed.')\n\n\n    if __name__ == '__main__':\n        connect()\nThe process in code.\nFirst, it reads database connection parameters from the mlteam.ini file then creates a new database connection by calling the connect() function, it then creates a new cursor and execute an SQL statement to get database version. After that, read the result set by calling the fetchone() method of the cursor object. Finally, close the communication with the database server by calling the close() method of the cursor and connection object.\nExecute code by running the connect.py file.\nYou should see such result in terminal:\n    Connecting to the PostgreSQL database...\n    PostgreSQL database version:\n    ('PostgreSQL 13, compiled by Visual C++ build 1914, 64-bit',)\n    Database connection closed."
  },
  {
    "objectID": "posts/setup-project/index.html",
    "href": "posts/setup-project/index.html",
    "title": "Set up projects for development and production environments",
    "section": "",
    "text": "This topic describes how to:\nUse separate projects to create development and production environments Many organizations have separate development and production environments so they can build and test new features without disturbing production traffic. In Optimizely, you can create separate projects for each environment to help with governance.\nWith separate development and production projects, your organization can safely build and QA experiments and Personalization campaigns in a development environment before deploying to production. This approach allows multiple stakeholders in your organization to act as gatekeepers for running new experiments in production.\nThis article describes how to set up projects for two separate environments and deploy experiments in that setup.\nSet up projects First, you‚Äôll start by creating two new projects: one for development and one for production.\nEach project will need its own snippet:\nCreate a project for your development environment.\nImplement the snippet in the head tag for that environment.\nAdd the collaborators who you'd like to have access to your development project.\nNext, create a project for your production environment.\nImplement the production project snippet in the head tag of the production environment.\nAdd collaborators who you'd like to have access to your production project.\nIf you‚Äôre using Optimizely, prepare each project by creating all pages, events, and audiences in each project. If you have an Optimizely Web Scale package, you can create events that are available across projects, which saves you time and makes it easier to keep events synchronized across your environments.\nCreate and deploy experiments Once you‚Äôve set up your development and production projects, use them to create, test, and deploy experiments. Here‚Äôs how:\nCreate an experiment in your development environment. If your development URLs are the same as the URLs used for your production environment, make sure that your production environment does not use the snippet from your development project.\nBuild and QA your new development experiment to make sure that everything works the way you‚Äôd like.\nBuild the experiment for your production project.\nWhen you‚Äôre ready, start the experiment in your production project!"
  },
  {
    "objectID": "posts/api-terms/index.html",
    "href": "posts/api-terms/index.html",
    "title": "API related terms",
    "section": "",
    "text": "Endpoint\nAn endpoint is nothing but the location(URL) where the actual resource is present.\nOrigin Server\nThe origin server is the actual server that contains the data and servers on the client‚Äôs request.\nThere may or may not be other intermediate servers included in the path.\nProxy Server\nServers have the ability to further pass your request to the other server.\nThese types of intermediate servers are known as proxy servers.\nDNS Server\nDNS stands for Domain Name System.\nAs computer devices are interacted using IP addresses, the DNS server provides the IP address of the requested URL.\nAPI key\nAn API key is a unique code for every user which lets you call an API.\nThe length of an API key could be anything.\nThe only rule is that these keys must be unique and not easy to guess.\nGenerally, API keys contain lower case and upper case letters with numbers.\nAPI Token\nThe API token is a unique identifier of an application requesting access to your API.\nAn API token is a form of authentication similar to a username/password.\nAccess token\nAn access token is used for authentication.\nApplications use an access token to authenticate themselves so that they can make an API call.\nSDK\nSDK stands for Software Development Kit.\nIt is a set of development tools that allows the creation of software or an application for a particular platform.\nSDK provides you with the whole package from compilers to debuggers to even a software development framework.\nRPC\nRemote Procedure Call (RPC) is the oldest client-server communication method in use today. Instead of the traditional HTTP call, RPC uses a function call.\nIt means that on the client-side, you invoke a function that is written on the server-side code.\nCORS\nCORS is an HTTP-based mechanism that lets you request data from one URL to a different URL.\nCheck out this note for more details: üëáüèª Screenshot from 2022-09-16 15-18-30\nAsync API\nAsyncAPI is an open-source project aimed at improving the current state of Event-Driven Architecture.\nThese APIs allow relatively time-consuming requests to be processed in the background while other requests are made.\nInternal API\nInternal API, also known as Private API is only accessible to the developers within an organization.\nAPI Caching\nAPI Caching is the ability to store copies of frequently accessed data in several places along the request-response path.\nExternal API\nExternal API, also known as Public API is accessible to all the developers outside the enterprise or organization.\nHTTP cookies\nAn HTTP cookie is a small piece of data created by the web server inside your browser.\nThe data inside a cookie has an ID that is unique to you and your computer. This ID helps the server know who the user is to send the data accordingly.\nAuthorization\nAuthorization always comes after authentication. It is the process of permitting users to access different resources from the server, and it‚Äôs not visible and changeable by the user.\nMicroservices\nA microservice is an application design that breaks up a monolithic architecture into small, self-containing services.\nOpenAPI spec\nIt is a format to define structure and syntax for REST APIs. It provides a standard that allows both humans and computers to discover and understand the service‚Äôs capabilities without access to source code, documentation, or traffic inspection.\nComposite API\nComposite API is a design approach in which we bundle multiple API requests into a single API call.\nAPI Versioning\nAPI versioning is the practice of managing changes in your API.\nYou should version your API if you are introducing any breaking changes. Clients can still access the old version, and their products will not break as soon as you launch a new release.\nAuthentication\nAuthentication and authorization are the two most confusing terms.\nAuthentication is validating the user to identify if they are who they claim to be.\nAPI Lifecycle\nAPI lifecycle is the entire lifespan of any particular API from its planning phase to when it gets stale."
  },
  {
    "objectID": "posts/naming-conventions-for-git/index.html",
    "href": "posts/naming-conventions-for-git/index.html",
    "title": "Naming conventions and pull request naming",
    "section": "",
    "text": "Branch Naming\nCommit Message\n\nMessage Header\nMessage Body\nMessage Footer\nMessage Example\n\n\n\nBranch Naming\nBranches created should be named using the following format:\n{story type}-{2-3 word summary}-{Asana work item id}\nstory-type - Indicates the context of the branch and can be one of:\n    ft == Feature\n    bg == Bug\n    ch == Chore\n    rf == Refactor\nstory-summary - Short 2-3 words summary about what the branch contains\nExample\nft-user-registration-TB1-I764\n\n\nCommit Message\nA commit message consists of a header, a body and a footer, separated by a blank line.\nAny line of the commit message cannot be longer than 100 characters! This allows the message to be easier to read on gitlab as well as in various git tools.\n<type>(<scope>): <subject>\n<BLANK LINE>\n<body>\n<BLANK LINE>\n<footer>\nThese rules are adopted from the AngularJS commit convention.\n\nMessage Header\nThe message header is a single line that contains succinct description of the change containing a type, an optional scope and a subject.\n##### <type> This describes the kind of change that this commit is providing.\nfeat (feature)\nfix (bug fix)\ndocs (documentation)\nstyle (formatting, missing semi colons, ‚Ä¶)\nrefactor\ntest (when adding missing tests)\nchore (maintain)\n#####<scope> Scope can be anything specifying place of the commit change. For example events, model_load, shiny_data_processing, authorization, authentication, loginPage, etc‚Ä¶\n#####<subject> This is a very short description of the change.\nuse imperative, present tense: ‚Äúchange‚Äù not ‚Äúchanged‚Äù nor ‚Äúchanges‚Äù\ndon‚Äôt capitalize first letter\nno dot (.) at the end\n\n\nMessage Body\njust as in subject use imperative, present tense: ‚Äúchange‚Äù not ‚Äúchanged‚Äù nor ‚Äúchanges‚Äù\nincludes motivation for the change and contrasts with previous behavior\nhttp://365git.tumblr.com/post/3308646748/writing-git-commit-messages\nhttp://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html Message Footer\n\n\nMessage Footer\nStatus changes should be listed on a separate line in the footer prefixed with #status  like this:\n[#TB1-I17 #status (in_progress | under_review)]\n\n\nMessage Example\nfeat(docker): implement exactly once delivery\n\nensure every event published to docker is delivered exactly once\nimplement error handling for failed delivery\n\n#status in_progress\nAsana cards\n\n\n\nPull Request Naming\nPull Request Title\nThe Pull Request title should be named using the following format:\n#[STORY_ID] [Story description]\nExample\n#TB1-I764 CREATE PULL REQUEST TEMPLATE\nPull Request Description Template\nThe description of the Pull Request should contain the following headings and corresponding content in Markdown format.\n#### What does this Pull Request do?\n#### Description of Task to be completed?\n#### How should this be manually tested?\n#### Any background context you want to provide?\n#### What are the relevant open projects stories e.g Asana?\n#### Screenshots (if appropriate)\n#### Questions:\nPull Request Etiquette\nIt is our belief that Pull Request reviews should not negatively impact a team‚Äôs ability to deliver features. Pull Requests that take too much time to get reviewed can hinder on a team‚Äôs progress. As such, we practice the following behaviours when raising Pull Requests:\nWhen I raise a Pull Request, I specifically assign a developer or engineering team as reviewer\nWhen I raise a Pull Request, I notify the reviewer(s) on telegram in a public channel\nThe reviewer(s) can re-assign the Pull Request to someone else (e.g. to a Senior Engineer)\nThe reviewer(s) has a 3 hours SLA to review the Pull Request\nIf SLA is not met, I can Pull the unreviewed Pull Request if and only if:\n    All the Pull Request checks are passing (CircleCI, CodeClimate, Test Coverage)\n    I communicate in #technology telegram channel that I am merging an unreviewed Pull Request\n    I immediately take ownership of fixing any issues that arise from merging the Pull Request"
  },
  {
    "objectID": "posts/http-respones-with-responses/index.html",
    "href": "posts/http-respones-with-responses/index.html",
    "title": "HTTP Status codes and the Information responses",
    "section": "",
    "text": "100 Continue\nThis interim response indicates that the client should continue the request or ignore the response if the request is already finished.\n101 Switching Protocols\nThis code is sent in response to an Upgrade request header from the client and indicates the protocol the server is switching to.\n102 Processing (WebDAV)\nThis code indicates that the server has received and is processing the request, but no response is available yet.\n103 Early Hints\nThis status code is primarily intended to be used with the Link header, letting the user agent start preloading resources while the server prepares a response.\n\nSuccessful responses\n200 OK\nThe request succeeded. The result meaning of ‚Äúsuccess‚Äù depends on the HTTP method:\n\nGET: The resource has been fetched and transmitted in the message body.\nHEAD: The representation headers are included in the response without any message body.\nPUT or POST: The resource describing the result of the action is transmitted in the message body.\nTRACE: The message body contains the request message as received by the server.\n\n201 Created\nThe request succeeded, and a new resource was created as a result. This is typically the response sent after POST requests, or some PUT requests.\n202 Accepted\nThe request has been received but not yet acted upon. It is noncommittal, since there is no way in HTTP to later send an asynchronous response indicating the outcome of the request. It is intended for cases where another process or server handles the request, or for batch processing.\n203 Non-Authoritative Information\nThis response code means the returned metadata is not exactly the same as is available from the origin server, but is collected from a local or a third-party copy. This is mostly used for mirrors or backups of another resource. Except for that specific case, the 200 OK response is preferred to this status.\n204 No Content\nThere is no content to send for this request, but the headers may be useful. The user agent may update its cached headers for this resource with the new ones.\n205 Reset Content\nTells the user agent to reset the document which sent this request.\n206 Partial Content\nThis response code is used when the Range header is sent from the client to request only part of a resource.\n207 Multi-Status (WebDAV)\nConveys information about multiple resources, for situations where multiple status codes might be appropriate.\n208 Already Reported (WebDAV)\nUsed inside a dav:propstat response element to avoid repeatedly enumerating the internal members of multiple bindings to the same collection.\n226 IM Used (HTTP Delta encoding)\nThe server has fulfilled a GET request for the resource, and the response is a representation of the result of one or more instance-manipulations applied to the current instance.\n\n\nRedirection message\n300 Multiple Choice\nThe request has more than one possible response. The user agent or user should choose one of them. (There is no standardized way of choosing one of the responses, but HTML links to the possibilities are recommended so the user can pick.)\n301 Moved Permanently\nThe URL of the requested resource has been changed permanently. The new URL is given in the response.\n302 Found\nThis response code means that the URI of requested resource has been changed temporarily. Further changes in the URI might be made in the future. Therefore, this same URI should be used by the client in future requests.\n303 See Other\nThe server sent this response to direct the client to get the requested resource at another URI with a GET request.\n304 Not Modified\nThis is used for caching purposes. It tells the client that the response has not been modified, so the client can continue to use the same cached version of the response.\n305 Use Proxy Deprecated\nDefined in a previous version of the HTTP specification to indicate that a requested response must be accessed by a proxy. It has been deprecated due to security concerns regarding in-band configuration of a proxy.\n306 unused\nThis response code is no longer used; it is just reserved. It was used in a previous version of the HTTP/1.1 specification.\n307 Temporary Redirect\nThe server sends this response to direct the client to get the requested resource at another URI with same method that was used in the prior request. This has the same semantics as the 302 Found HTTP response code, with the exception that the user agent must not change the HTTP method used: if a POST was used in the first request, a POST must be used in the second request.\n308 Permanent Redirect\nThis means that the resource is now permanently located at another URI, specified by the Location: HTTP Response header. This has the same semantics as the 301 Moved Permanently HTTP response code, with the exception that the user agent must not change the HTTP method used: if a POST was used in the first request, a POST must be used in the second request.\n\n\nClient error responses\n400 Bad Request\nThe server cannot or will not process the request due to something that is perceived to be a client error (e.g., malformed request syntax, invalid request message framing, or deceptive request routing).\n401 Unauthorized\nAlthough the HTTP standard specifies ‚Äúunauthorized‚Äù, semantically this response means ‚Äúunauthenticated‚Äù. That is, the client must authenticate itself to get the requested response.\n402 Payment Required Experimental\nThis response code is reserved for future use. The initial aim for creating this code was using it for digital payment systems, however this status code is used very rarely and no standard convention exists.\n403 Forbidden\nThe client does not have access rights to the content; that is, it is unauthorized, so the server is refusing to give the requested resource. Unlike 401 Unauthorized, the client‚Äôs identity is known to the server.\n404 Not Found\nThe server can not find the requested resource. In the browser, this means the URL is not recognized. In an API, this can also mean that the endpoint is valid but the resource itself does not exist. Servers may also send this response instead of 403 Forbidden to hide the existence of a resource from an unauthorized client. This response code is probably the most well known due to its frequent occurrence on the web.\n405 Method Not Allowed\nThe request method is known by the server but is not supported by the target resource. For example, an API may not allow calling DELETE to remove a resource.\n406 Not Acceptable\nThis response is sent when the web server, after performing server-driven content negotiation, doesn‚Äôt find any content that conforms to the criteria given by the user agent.\n407 Proxy Authentication Required\nThis is similar to 401 Unauthorized but authentication is needed to be done by a proxy.\n408 Request Timeout\nThis response is sent on an idle connection by some servers, even without any previous request by the client. It means that the server would like to shut down this unused connection. This response is used much more since some browsers, like Chrome, Firefox 27+, or IE9, use HTTP pre-connection mechanisms to speed up surfing. Also note that some servers merely shut down the connection without sending this message.\n409 Conflict\nThis response is sent when a request conflicts with the current state of the server.\n410 Gone\nThis response is sent when the requested content has been permanently deleted from server, with no forwarding address. Clients are expected to remove their caches and links to the resource. The HTTP specification intends this status code to be used for ‚Äúlimited-time, promotional services‚Äù. APIs should not feel compelled to indicate resources that have been deleted with this status code.\n411 Length Required\nServer rejected the request because the Content-Length header field is not defined and the server requires it.\n412 Precondition Failed\nThe client has indicated preconditions in its headers which the server does not meet.\n413 Payload Too Large\nRequest entity is larger than limits defined by server. The server might close the connection or return an Retry-After header field.\n414 URI Too Long\nThe URI requested by the client is longer than the server is willing to interpret.\n415 Unsupported Media Type\nThe media format of the requested data is not supported by the server, so the server is rejecting the request.\n416 Range Not Satisfiable\nThe range specified by the Range header field in the request cannot be fulfilled. It‚Äôs possible that the range is outside the size of the target URI‚Äôs data.\n417 Expectation Failed\nThis response code means the expectation indicated by the Expect request header field cannot be met by the server.\n418 I'm a teapot\nThe server refuses the attempt to brew coffee with a teapot.\n421 Misdirected Request\nThe request was directed at a server that is not able to produce a response. This can be sent by a server that is not configured to produce responses for the combination of scheme and authority that are included in the request URI.\n422 Unprocessable Entity (WebDAV)\nThe request was well-formed but was unable to be followed due to semantic errors.\n423 Locked (WebDAV)\nThe resource that is being accessed is locked.\n424 Failed Dependency (WebDAV)\nThe request failed due to failure of a previous request.\n425 Too Early Experimental\nIndicates that the server is unwilling to risk processing a request that might be replayed.\n426 Upgrade Required\nThe server refuses to perform the request using the current protocol but might be willing to do so after the client upgrades to a different protocol. The server sends an Upgrade header in a 426 response to indicate the required protocol(s).\n428 Precondition Required\nThe origin server requires the request to be conditional. This response is intended to prevent the ‚Äòlost update‚Äô problem, where a client GETs a resource‚Äôs state, modifies it and PUTs it back to the server, when meanwhile a third party has modified the state on the server, leading to a conflict.\n429 Too Many Requests\nThe user has sent too many requests in a given amount of time (‚Äúrate limiting‚Äù).\n431 Request Header Fields Too Large\nThe server is unwilling to process the request because its header fields are too large. The request may be resubmitted after reducing the size of the request header fields.\n451 Unavailable For Legal Reasons\nThe user agent requested a resource that cannot legally be provided, such as a web page censored by a government.\n\n\nServer error responses\n500 Internal Server Error\nThe server has encountered a situation it does not know how to handle.\n501 Not Implemented\nThe request method is not supported by the server and cannot be handled. The only methods that servers are required to support (and therefore that must not return this code) are GET and HEAD.\n502 Bad Gateway\nThis error response means that the server, while working as a gateway to get a response needed to handle the request, got an invalid response.\n503 Service Unavailable\nThe server is not ready to handle the request. Common causes are a server that is down for maintenance or that is overloaded. Note that together with this response, a user-friendly page explaining the problem should be sent. This response should be used for temporary conditions and the Retry-After HTTP header should, if possible, contain the estimated time before the recovery of the service. The webmaster must also take care about the caching-related headers that are sent along with this response, as these temporary condition responses should usually not be cached.\n504 Gateway Timeout\nThis error response is given when the server is acting as a gateway and cannot get a response in time.\n505 HTTP Version Not Supported\nThe HTTP version used in the request is not supported by the server.\n506 Variant Also Negotiates\nThe server has an internal configuration error: the chosen variant resource is configured to engage in transparent content negotiation itself, and is therefore not a proper end point in the negotiation process.\n507 Insufficient Storage (WebDAV)\nThe method could not be performed on the resource because the server is unable to store the representation needed to successfully complete the request.\n508 Loop Detected (WebDAV)\nThe server detected an infinite loop while processing the request.\n510 Not Extended\nFurther extensions to the request are required for the server to fulfill it.\n511 Network Authentication Required\nIndicates that the client needs to authenticate to gain network access."
  },
  {
    "objectID": "posts/rest-api/index.html",
    "href": "posts/rest-api/index.html",
    "title": "REST APIs",
    "section": "",
    "text": "REST API\nIt Is a web service based on REST architecture that allows communication between different systems.\nIt uses HTTP requests to GET, PUT, POST, and DELETE data. REST API is often used in web applications to access data from a server.\nAPI Client\nAn API Client is a software program that makes it easy to work with Application Programming Interfaces (APIs).\nIt can be used to access data or perform actions on behalf of a user.\nAPI Clients are often used by developers to test APIs.\nAPI Resource\nAn API resource is a specific type of data that can be accessed by an application programming interface (API). API Server\nAn API server allows two different systems to communicate with each other.\nIn most cases, an API server enables a web application to interact with a database.\nAPI Scalability\nAPI scalability refers to the ability of an API to handle increased loads of data or traffic without adversely affecting performance.\nA scalable API can handle large amounts of data and traffic without compromising speed or functionality.\nStateless API\nA stateless API is an API that does not maintain a state between requests.\nEach request is independent of any other request, and state information is not stored on the server.\nAPI Cache\nAn API is cacheable if the data it returns can be stored in a cache.\nCache allows the same data to be returned for multiple requests without having to fetch it from the original source each time.\nCaching can improve performance.\nLayered System\nA layered system, means that each layer is responsible for a specific set of tasks.\nThe most common layers are the presentation layer, the business logic layer, and the data access layer."
  }
]